{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\n\nimport scipy as sp\nimport pandas as pd\nimport re\nimport numpy as np\n\n\n# Data visualization\nimport matplotlib as mlt\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Scalers\nfrom sklearn.preprocessing import StandardScaler\n\n#discritization\nfrom sklearn.preprocessing import LabelEncoder\n\n#Models\nfrom sklearn.ensemble import RandomForestClassifier\n\n#evaluation\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-18T11:44:47.458802Z","iopub.execute_input":"2022-06-18T11:44:47.45989Z","iopub.status.idle":"2022-06-18T11:44:47.471452Z","shell.execute_reply.started":"2022-06-18T11:44:47.459841Z","shell.execute_reply":"2022-06-18T11:44:47.470732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv (r'../input/titanic/train.csv')\ntest = pd.read_csv (r'../input/titanic/test.csv')\ntrain.head(15)\n\n# check missing data\ndef missing_data(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()/data.isnull().count()*100)\n    types = [str(data[i].dtype) for i in data.columns]\n    df = pd.DataFrame({'Total':total, 'Precent':percent, 'Types':types})\n    return(sp.transpose(df))\n\nmissing_data(train)\nmissing_data(test)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-18T12:00:42.091508Z","iopub.execute_input":"2022-06-18T12:00:42.092646Z","iopub.status.idle":"2022-06-18T12:00:42.137818Z","shell.execute_reply.started":"2022-06-18T12:00:42.092601Z","shell.execute_reply":"2022-06-18T12:00:42.136869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Describe dataset** \n* 11 features contains categorical and continuous and ordinal features.\n* Passengerid may be irralevant\n* need extract information from categorical features like \"Name\",\"Ticket\",\"Cabin\"\n* categorical & ordinal features like \"Embarked\",\"Sex\"need discritization\n\n\n**Handle missing values** \n\nWe notice \"Age\",\"Fare\" ,\"Embarked\", and \"Cabin\" has missing values, we first need to handle the missing values.\n\n*  \"Age\" and \"Fare\"(continuous)\n\nWe construct densiity plot to see its distribution.The ditribution of \"Fare\" is right skewed, hence we use median imputation.\n\n* \"Cabin\" and \"Embarked\" (categorical)\n\nSimply impute \"no values\" to resolve \"Cabin\" missing values. For \"Embarked\", we use the most frequent value imputation.","metadata":{}},{"cell_type":"code","source":"#missing value imputation\ny_train = train['Survived']\nX_train = train.drop(columns='Survived')\ndata = pd.concat([X_train, test])\ndata['Age'].fillna(data['Age'].median(), inplace=True)\ndata['Fare'].fillna(data['Fare'].median(), inplace=True)\ndata['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\ndata['Cabin'].fillna('no value', inplace=True)\ndata['Sex'] = data['Sex'].apply(lambda x: 1 if x == 'male' else 0)\ndata[\"FamilySize\"] = data[\"SibSp\"] + data[\"Parch\"] + 1\n\nregex = \"([A-Za-z]+)\\.\"\ndef get_title(row):\n    match = re.search(regex, str(row))\n    title = match.group(0);\n    return title\ndata['Title'] = data.Name.apply(lambda x: get_title(x))\ndata['Title'] .value_counts()\n\ndata['Title'] = data['Title'].replace('Mlle.','Miss.')\ndata['Title'] = data['Title'].replace('Ms.','Miss.')  \ndata['Title'] = data['Title'].replace('Mme.','Mrs.')\ndata['Title'] = data['Title'].replace(['Capt.','Col.','Major.'],'Army.')\ndata['Title'] = data['Title'].replace(['Countess.','Don.','Jonkheer.','Lady.','Sir.'],'Noble.')\ndata = data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp', 'Parch'], axis = 1)# drop unwanted columns that do not contribute to survivability\n\n#split the train test dataset for traindataset analysis\nX_train = data.loc[:X_train.index[-1]]\nX_test = data.loc[X_train.index[-1]:][1:]\ntrain = pd.concat([y_train, X_train], axis=1)\nX_train","metadata":{"execution":{"iopub.status.busy":"2022-06-18T12:00:56.226549Z","iopub.execute_input":"2022-06-18T12:00:56.227049Z","iopub.status.idle":"2022-06-18T12:00:56.285449Z","shell.execute_reply.started":"2022-06-18T12:00:56.227013Z","shell.execute_reply":"2022-06-18T12:00:56.284331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Anlysis the train dataset**\n\n* seems like sex, pclass and fare is more correlated with survival\n* Embark doesn't seems very helpful\n* children seems have higher survivality -> need to add a binary feature \n* people with titles(noble) ","metadata":{}},{"cell_type":"code","source":"print('Total number of passangers who survivded : ', len(train[train['Survived'] == 1]))\nprint('Total number of passangers who died : ', len(train[train['Survived'] == 0]))\n\nprint('Total percentage of male passangers who survivded : ', 100*np.mean(train['Survived'][train['Sex'] == 1]))\nprint('Total percentage of female passangers who survivded : ', 100*np.mean(train['Survived'][train['Sex'] == 0]))\n\nprint('Total percentage of passangers who survivded from first class : ', 100*np.mean(train['Survived'][train['Pclass'] == 1]))\nprint('Total percentage of passangers who survivded from second class : ', 100*np.mean(train['Survived'][train['Pclass'] == 2]))\nprint('Total percentage of passangers who survivded from third class : ', 100*np.mean(train['Survived'][train['Pclass'] == 3]))\n\nprint('Total percentage of passangers who survivded below 18 years : ', 100*np.mean(train['Survived'][train['Age'] < 18]))\nprint('Total percentage of passangers who survivded above 18 years : ', 100*np.mean(train['Survived'][train['Age'] > 18]))\n\nprint('Percentage of average survival:\\n\\n{}\\n'.format(train.groupby('Title')['Survived'].mean()*100))\nprint('Percentage of average survival:\\n\\n{}\\n'.format(train.groupby('Embarked')['Survived'].mean()*100))\nprint('Percentage of average survival:\\n\\n{}\\n'.format(train.groupby('Title')['Survived'].mean()*100))\n\nfor i in train:\n    plt.figure(figsize=(13,7))\n    sns.histplot(data = train, x=i, kde=True, hue = 'Survived', multiple='stack')\n    plt.title(i)\n    plt.show()\nplt.figure(figsize = (10, 8))\nsns.heatmap(train.corr(), annot = True)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T11:44:50.870057Z","iopub.execute_input":"2022-06-18T11:44:50.870827Z","iopub.status.idle":"2022-06-18T11:44:54.967461Z","shell.execute_reply.started":"2022-06-18T11:44:50.870769Z","shell.execute_reply":"2022-06-18T11:44:54.966399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Feature engineering**","metadata":{}},{"cell_type":"code","source":"# add a new column indicating adult or not\ndef children(df): \n    children = [];\n    for i in range(len(df['Age'])):\n        X = df['Age'].iloc[i];\n        if(X>=18):\n            children.append(0);\n        else:\n            children.append(1);\n    df['children'] = children;\n    return df\nchildren(data)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T12:10:23.776768Z","iopub.execute_input":"2022-06-18T12:10:23.777269Z","iopub.status.idle":"2022-06-18T12:10:23.822362Z","shell.execute_reply.started":"2022-06-18T12:10:23.77722Z","shell.execute_reply":"2022-06-18T12:10:23.821357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#discretization\nle = LabelEncoder()\ndata[\"Embarked\"] = le.fit_transform(data[\"Embarked\"])\ndata[\"Title\"] = le.fit_transform(data[\"Title\"])\ndata","metadata":{"execution":{"iopub.status.busy":"2022-06-18T12:10:33.575094Z","iopub.execute_input":"2022-06-18T12:10:33.575612Z","iopub.status.idle":"2022-06-18T12:10:33.596614Z","shell.execute_reply.started":"2022-06-18T12:10:33.57557Z","shell.execute_reply":"2022-06-18T12:10:33.595616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#scaler \nsc = StandardScaler()\ntrain_len = X_train.index[-1]\nX_train = data.loc[:train_len]\nsc =sc.fit(X_train[X_train.columns], y_train)\ndata[data.columns] = sc.transform(data[data.columns])\n\nX_train = data.loc[:train_len]\nX_test = data.loc[train_len:][1:]\ntrain = pd.concat([y_train, X_train], axis=1)\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-06-18T12:10:41.264936Z","iopub.execute_input":"2022-06-18T12:10:41.265386Z","iopub.status.idle":"2022-06-18T12:10:41.298274Z","shell.execute_reply.started":"2022-06-18T12:10:41.265353Z","shell.execute_reply":"2022-06-18T12:10:41.297211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.28, random_state = 42)\n\n#scaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)\n\n#RF mdoel\nRFmodel = RandomForestClassifier(n_estimators=100, max_depth=len(train.columns)-1, random_state=1)\nRFmodel.fit(X_train, y_train);\nskf = StratifiedKFold(n_splits=10)\nresults = cross_val_score(RFmodel, X_val, y_val, cv=skf)\n\nprint(\"train accuracy: \\n \", metrics.accuracy_score(y_train, RFmodel.predict(X_train)))\nprint(\"cross validation accuracy:  \\n\",results)\nprint(\"Avg cross validation accuracy:  \\n\",np.mean(results))\nplot_confusion_matrix(RFmodel, X_val, y_val)  ","metadata":{"execution":{"iopub.status.busy":"2022-06-18T12:10:50.150756Z","iopub.execute_input":"2022-06-18T12:10:50.151241Z","iopub.status.idle":"2022-06-18T12:10:52.509617Z","shell.execute_reply.started":"2022-06-18T12:10:50.151205Z","shell.execute_reply":"2022-06-18T12:10:52.508571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import svm\nSVMmodel= svm.SVC(kernel='linear',decision_function_shape='ovo', C=1) # Linear Kernel\nSVMmodel.fit(X_train, y_train)\n\n\nskf = StratifiedKFold(n_splits=10)\nresults = cross_val_score(SVMmodel, X_val, y_val, cv=skf)\nprint(\"train accuracy: \\n \", metrics.accuracy_score(y_train, SVMmodel.predict(X_train)))\nprint(\"cross validation accuracy:  \\n\",results)\nprint(\"Avg cross validation accuracy:  \\n\",np.mean(results))\nplot_confusion_matrix(SVMmodel, X_val, y_val)  \n","metadata":{"execution":{"iopub.status.busy":"2022-06-18T12:11:02.1313Z","iopub.execute_input":"2022-06-18T12:11:02.131833Z","iopub.status.idle":"2022-06-18T12:11:02.434463Z","shell.execute_reply.started":"2022-06-18T12:11:02.131789Z","shell.execute_reply":"2022-06-18T12:11:02.43348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import StackingClassifier\nestimators = [('rf',RFmodel), ('svr', SVMmodel)]\nclf = StackingClassifier(estimators=estimators, final_estimator=RFmodel)\nclf.fit(X_train, y_train).score(X_val, y_val)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T12:11:50.63997Z","iopub.execute_input":"2022-06-18T12:11:50.640454Z","iopub.status.idle":"2022-06-18T12:11:52.189433Z","shell.execute_reply.started":"2022-06-18T12:11:50.640419Z","shell.execute_reply":"2022-06-18T12:11:52.1884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test = clf.predict(X_test)\noutput = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': y_test})\noutput.head()\noutput.to_csv('./submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T12:11:55.005394Z","iopub.execute_input":"2022-06-18T12:11:55.006327Z","iopub.status.idle":"2022-06-18T12:11:55.058517Z","shell.execute_reply.started":"2022-06-18T12:11:55.006275Z","shell.execute_reply":"2022-06-18T12:11:55.057669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}